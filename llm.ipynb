{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "24591b4f-0a43-4baa-8b3c-6732c7c9212f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "from openai import OpenAI\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "\n",
    "from prepare_plasticc import config\n",
    "from tokenizer import LCTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "141f2627-9c76-4712-8e1a-ffa9aa2c6786",
   "metadata": {},
   "outputs": [],
   "source": [
    "api_key = os.environ.get('OPENAI_API_KEY', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "84119dc2-5789-45c8-93f3-c85abc2b0a8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = OpenAI(api_key=api_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f4336570-7390-470e-90fb-901650646ad4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_meta = pd.read_csv('plasticc/plasticc_train_metadata.csv.gz')\n",
    "df_meta = df_meta.sample(frac=1, random_state=42)\n",
    "\n",
    "df = pd.read_csv('plasticc/plasticc_train_lightcurves.csv.gz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "21050853-564c-498d-b7e4-25d09063f490",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_size= int(0.8 * len(df_meta))\n",
    "val_size = int(0.1 * len(df_meta))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce777e46-9399-4425-932f-621b9e00a0f6",
   "metadata": {},
   "source": [
    "# Tokens "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "01c97777-932e-4dde-b9f4-438f93a4c426",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = LCTokenizer(-10000, 10000, 500, 1000, 500, bands=config[\"bands\"],\n",
    "                            transform=np.arcsinh, inverse_transform=np.sinh,\n",
    "                            min_sn=3, window_size=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "c37711e7-7e31-4ef3-837e-7460f0f32e85",
   "metadata": {},
   "outputs": [],
   "source": [
    "system = 'You are an assistant that can analyse tokens that encode the flux and time intervals between observations in different passbands of the LSST. You can also use the photometric redshift. \\\n",
    "Use this data to infer the class of the object. Answers should be 6, 15, 16, 42, 52, 53, 62, 64, 65, 67, 88, 90, 92, 95.'\n",
    "\n",
    "train_messages = []\n",
    "val_messages = []\n",
    "for i, row in df_meta.iterrows():\n",
    "    df_object = df.loc[(df[\"object_id\"] == row[\"object_id\"]), :]\n",
    "    tokens = tokenizer.encode(df_object)\n",
    "    message = []\n",
    "    message.append({\n",
    "        'role': 'system',\n",
    "        'content': system\n",
    "    })\n",
    "    message.append({\n",
    "        'role': 'user',\n",
    "        'content': 'The photometric redshift is %s. The tokens are %s' % (row['hostgal_photoz'], json.dumps(tokens))  \n",
    "    })\n",
    "    message.append({\n",
    "        'role': 'assistant',\n",
    "        'content': json.dumps(int(row['true_target']))\n",
    "    })\n",
    "    if i <= train_size:\n",
    "        train_messages.append({'messages': message})\n",
    "    elif train_size < i <= train_size + val_size:\n",
    "        val_messages.append({'messages':message})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "404ec26d-8bb0-465c-a74d-48bfeb4d6c12",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"chatgpt/train_data_tokens.jsonl\", 'w') as f:\n",
    "    for message in train_messages:\n",
    "        f.write(json.dumps(message) + \"\\n\")\n",
    "        \n",
    "with open(\"chatgpt/val_data_tokens.jsonl\", 'w') as f:\n",
    "    for message in val_messages:\n",
    "        f.write(json.dumps(message) + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "aa77cf33-9117-45a1-8468-4cdcc743d406",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n",
      "50\n",
      "51\n",
      "52\n",
      "53\n",
      "54\n",
      "55\n",
      "56\n",
      "57\n",
      "58\n",
      "59\n",
      "60\n",
      "61\n",
      "62\n",
      "63\n",
      "64\n",
      "65\n",
      "66\n",
      "67\n",
      "68\n",
      "69\n",
      "70\n",
      "71\n",
      "72\n",
      "73\n",
      "74\n",
      "75\n",
      "76\n",
      "77\n",
      "78\n",
      "79\n",
      "80\n",
      "81\n",
      "82\n",
      "83\n",
      "84\n",
      "85\n",
      "86\n",
      "87\n",
      "88\n",
      "89\n",
      "90\n",
      "91\n",
      "92\n",
      "93\n",
      "94\n",
      "95\n",
      "96\n",
      "97\n",
      "98\n",
      "99\n"
     ]
    }
   ],
   "source": [
    "y_pred, y_true = [], []\n",
    "for i, message in enumerate(val_messages[0:100]):\n",
    "    print(i)\n",
    "    resp = client.chat.completions.create(\n",
    "                    #model='ft:gpt-3.5-turbo-0125:personal:plasticc4:9GwzYWLy', # 100\n",
    "                    model='ft:gpt-3.5-turbo-0125:personal:plasticc:9GoMgdwp', # 500\n",
    "                    messages=message['messages'][:2],\n",
    "                    temperature=0,\n",
    "    )\n",
    "    y_pred.append(int(resp.choices[0].message.content))\n",
    "    y_true.append(int(message['messages'][2]['content']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "35f20451-594c-4363-a756-9d2148a91143",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[10,  0,  0,  0,  1,  0,  1,  0,  0,  1,  0,  0],\n",
       "       [ 0, 13,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
       "       [ 3,  0,  8,  0,  3,  0,  0,  0,  0,  1,  0,  0],\n",
       "       [ 0,  0,  0,  0,  1,  0,  0,  0,  0,  2,  0,  0],\n",
       "       [ 0,  0,  1,  0,  3,  0,  0,  0,  0,  0,  0,  0],\n",
       "       [ 0,  0,  0,  0,  0,  0,  0,  0,  0,  1,  0,  0],\n",
       "       [ 0,  2,  0,  0,  0,  0,  9,  0,  1,  0,  0,  0],\n",
       "       [ 0,  0,  0,  0,  2,  0,  0,  0,  0,  0,  0,  0],\n",
       "       [ 0,  0,  0,  0,  0,  0,  0,  0,  1,  0,  0,  0],\n",
       "       [ 1,  1,  8,  0,  4,  0,  2,  0,  0, 11,  0,  0],\n",
       "       [ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  3,  0],\n",
       "       [ 1,  0,  2,  0,  1,  0,  1,  0,  0,  0,  0,  1]])"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "bff689eb-4c95-4af2-afb6-413f1a953296",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.59"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "a0bff0f1-a947-4380-88c3-cae5b136a874",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'messages': [{'role': 'system',\n",
       "   'content': 'You are an assistant that can analyse tokens that encode the flux and time intervals between observations in different passbands of the LSST. You can also use the photometric redshift. Use this data to infer the class of the object. Answers should be 6, 15, 16, 42, 52, 53, 62, 64, 65, 67, 88, 90, 92, 95.'},\n",
       "  {'role': 'user',\n",
       "   'content': 'The photometric redshift is 0.424. The tokens are [93, 678, 48, 274, 12, 274, 35, 578, 45, 372, 12, 475, 58, 570, 19, 471, 48, 366, 28, 366, 43, 468]'},\n",
       "  {'role': 'assistant', 'content': '90'}]}"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_messages[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55732747-e5d1-4dbe-b397-f83656682b23",
   "metadata": {},
   "source": [
    "#Â Fluxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "844dac72-6f51-47f1-bd43-dc646c009ff7",
   "metadata": {},
   "outputs": [],
   "source": [
    "system = 'You are an assistant that can analyse time, passband and flux observations from the LSST.  You can also use the photometric redshift.\\\n",
    "Use them to infer the class of the object. Answers should be 6, 15, 16, 42, 52, 53, 62, 64, 65, 67, 88, 90, 92, 95.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4a238235-1480-4284-8ccc-8ca3aa48cbde",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_messages = []\n",
    "val_messages = []\n",
    "\n",
    "for i, row in df_meta.iterrows():\n",
    "    df_object = df.loc[(df[\"object_id\"] == row[\"object_id\"]) & (df[\"detected_bool\"] == 1), :].reset_index(drop=True)\n",
    "    df_object.loc[:, 'mjd'] = df_object.loc[:, 'mjd'] - min(df_object['mjd'])\n",
    "    df_object.loc[:, 'flux'] = round(np.arcsinh(df_object.loc[:, 'flux']), 1)\n",
    "    df_object.loc[:, 'mjd'] = round(df_object.loc[:, 'mjd'], 1)\n",
    "    obs = df_object[['mjd', 'passband', 'flux']].to_json(orient=\"split\", index=False)\n",
    "    message = []\n",
    "    message.append({\n",
    "        'role': 'system',\n",
    "        'content': system\n",
    "    })\n",
    "    message.append({\n",
    "        'role': 'user',\n",
    "        'content': 'The photometric redshift is %s. The measurements are %s' % (row['hostgal_photoz'], obs) \n",
    "    })\n",
    "    message.append({\n",
    "        'role': 'assistant',\n",
    "        'content': json.dumps(int(row['true_target']))\n",
    "    })\n",
    "    if i <= train_size:\n",
    "        train_messages.append({'messages': message})\n",
    "    elif train_size < i <= train_size + val_size:\n",
    "        val_messages.append({'messages':message})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b5846ef0-05ba-4cc2-b0d2-1b2de55cd284",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'messages': [{'role': 'system',\n",
       "   'content': 'You are an assistant that can analyse time, passband and flux observations from the LSST.  You can also use the photometric redshift.Use them to infer the class of the object. Answers should be 6, 15, 16, 42, 52, 53, 62, 64, 65, 67, 88, 90, 92, 95.'},\n",
       "  {'role': 'user',\n",
       "   'content': 'The photometric redshift is 0.0. The measurements are {\"columns\":[\"mjd\",\"passband\",\"flux\"],\"data\":[[0.0,3,-8.7],[77.7,4,-8.2],[353.8,2,-6.3],[396.0,3,-8.4],[458.8,2,-9.4]]}'},\n",
       "  {'role': 'assistant', 'content': '16'}]}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_messages[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ee462abf-88f7-442e-ab3e-74289fb023ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"chatgpt/train_data_fluxes.jsonl\", 'w') as f:\n",
    "    for message in train_messages:\n",
    "        f.write(json.dumps(message) + \"\\n\")\n",
    "with open(\"chatgpt/val_data_fluxes.jsonl\", 'w') as f:\n",
    "    for message in val_messages:\n",
    "        f.write(json.dumps(message) + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "290028ee-b841-4d07-8b96-cc366db633f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n"
     ]
    }
   ],
   "source": [
    "y_pred, y_true = [], []\n",
    "for i, message in enumerate(val_messages[0:10]):\n",
    "    print(i)\n",
    "    resp = client.chat.completions.create(\n",
    "                    model='ft:gpt-3.5-turbo-0125:personal:plasticc2:9GuAZ5lr',\n",
    "                    messages=message['messages'][:2],\n",
    "                    temperature=0,\n",
    "    )\n",
    "    y_pred.append(int(resp.choices[0].message.content))\n",
    "    y_true.append(int(message['messages'][2]['content']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "cc2a8fd6-c296-470b-9231-0c6c61601c60",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, 0, 1, 0, 0],\n",
       "       [0, 0, 0, 0, 1, 1, 0],\n",
       "       [0, 0, 0, 0, 1, 0, 0],\n",
       "       [0, 0, 0, 0, 1, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 3, 1, 0],\n",
       "       [0, 0, 0, 0, 0, 1, 0]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "41ad4d10-31f0-4957-acb9-172acafebe03",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.1"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4093ca7f-1dbb-4037-81b9-0fbbe2dd160d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
